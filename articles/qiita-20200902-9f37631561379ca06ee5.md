---
title: "PyTorchã®DataLoaderã§BrokenPipeErrorã‚’å›é¿ã™ã‚‹æ–¹æ³•ãƒ¡ãƒ¢"
emoji: "ğŸ˜€"
type: "tech"
topics: [Python,DeepLearning,PyTorch]
published: true
---
PyTorchã®DataLoaderã¯ï¼Œãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹ã§ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ãŒå‡ºæ¥ã‚‹ä»•çµ„ã¿ãŒå‚™ã‚ã£ã¦ã„ã‚‹ï¼Windowsã§ãã‚Œã‚’åˆ©ç”¨ã—ã‚ˆã†ã¨ã—ãŸã¨ã“ã‚ï¼Œ[ã“ã¡ã‚‰](https://github.com/pytorch/pytorch/issues/31465)ã¨åŒã˜ã‚ˆã†ãªã‚¨ãƒ©ãƒ¼ã‚’åã„ã¦å‹•ä½œã—ãªã‹ã£ãŸï¼ãã“ã§è‰²ã€…èª¿ã¹ã¦è§£æ±ºã‚’è¡Œã£ãŸãŸã‚ï¼Œãã®æ–¹æ³•ã‚’ãƒ¡ãƒ¢ã™ã‚‹ï¼

- å‹•ä½œç’°å¢ƒ
    - OS: Windows10 Home(ãƒãƒ¼ã‚¸ãƒ§ãƒ³ 2004)
    - Python: 3.7.3
    - PyTorch: 1.3.1


# DataLoaderã®ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹
[å…¬å¼ã®Docs](https://pytorch.org/docs/1.3.1/data.html)ã‹ã‚‰å¼•ç”¨ã™ã‚‹ã¨
>A `DataLoader` uses single-process data loading by default.

>Within a Python process, the Global Interpreter Lock (GIL) prevents true fully parallelizing Python code across threads. To avoid blocking computation code with data loading, PyTorch provides an easy switch to perform multi-process data loading by simply setting the argument `num_workers` to a positive integer.

ã¨ã®ã“ã¨ï¼éå¸¸ã«ã–ã£ãã‚Šè¨€ã†ã¨ï¼ŒDataLoaderã‚¯ãƒ©ã‚¹ã®`num_workers`ã¨ã„ã†å¤‰æ•°ã®å€¤ã‚’1ä»¥ä¸Šã«ã™ã‚Œã°ï¼Œãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã‚’ä¸¦åˆ—åŒ–ã§ãã‚‹ï¼Œã¨ã„ã†ã“ã¨ã§ã‚ã‚‹ï¼
# BrokenPipeError
ãã“ã§ï¼Œ`num_workers`ã‚’1ä»¥ä¸Šã®å€¤ã«è¨­å®šã—ã¦å‹•ã‹ã—ãŸã¨ã“ã‚ï¼Œ

```
BrokenPipeError: [Errno 32] Broken pipe
```
ã¨ã‚¨ãƒ©ãƒ¼ã‚’åã„ã¦å‹•ä½œã—ãªã‹ã£ãŸï¼
[Pytorchã®Datasetã‚’DataLoaderã§ä¸¦åˆ—ã«èª­ã¿è¾¼ã¿ãŸã„ã¨ãã®ã‚¨ãƒ©ãƒ¼ï¼ˆWindowsï¼‰](https://qiita.com/fmfm_mdk/items/726aeacf8f6efe10009e)ã‚’å‚è€ƒã«ï¼Œ`Dataset`ã®å®šç¾©ã‚’åˆ¥ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§è¡Œã£ã¦ã‚‚åŒæ§˜ã®ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸï¼
# è§£æ±ºæ³•
[ã“ã¡ã‚‰](https://discourse.pymc.io/t/multiprocessing-windows-10-brokenpipeerror-errno-32-broken-pipe/2259)ã‚’å‚è€ƒã«ã™ã‚‹ã¨ï¼Œã©ã†ã‚„ã‚‰Windowsã§ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹ã‚’è¡Œã†å ´åˆï¼Œ`if __name__ == "__main__"`å†…ã§ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹ã‚’è¡Œã†é–¢æ•°ã‚’å®Ÿè¡Œã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã¨ã®ã“ã¨ï¼

ä¿®æ­£å‰

```train.py
from torch.utils.data import DataLoader
from dataloader import MyDataset #ä½œæˆã—ãŸdataset

def train():
    dataset = MyDataset()
    train_loader = DataLoader(dataset, num_workers=2, shuffle=True,
                              batch_size=4,
                              pin_memory=True,
                              drop_last=True)

    for batch in train_loader:
        #do some process...

if __name__ == "__main__":
    train()
```

ä¿®æ­£å¾Œ

```train.py
from torch.utils.data import DataLoader
from dataloader import MyDataset #ä½œæˆã—ãŸdataset

def train(train_loader):
    for batch in train_loader:
        #do some process...

if __name__ == "__main__":
    #dataset, DataLoaderã‚’ç§»å‹•
    dataset = MyDataset()
    train_loader = DataLoader(dataset, num_workers=2, shuffle=True,
                              batch_size=4,
                              pin_memory=True,
                              drop_last=True)

    train(train_loader)
```

DataLoaderã®å ´åˆï¼Œã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ç”Ÿæˆã‚’`if __name__ == "__main__"`å†…ã§è¡Œã£ã¦ã„ã‚Œã°ï¼Œãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿è‡ªä½“ã¯åˆ¥ã®é–¢æ•°å†…ã§å®Ÿè¡Œã—ã¦ã‚‚ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹ã¯å‹•ä½œã—ãŸï¼
# ã¾ã¨ã‚
Windowsç’°å¢ƒã§DataLoaderã®ä¸¦åˆ—åŒ–ã™ã‚‹ãŸã‚ã®ãƒ¡ãƒ¢ã‚’è¨˜ã—ãŸï¼æ·±å±¤å­¦ç¿’å‘¨ã‚Šã§ã¯ï¼ŒWindowsã ã¨å‹•ä½œã—ãªã„ã¾ãŸã¯å°‘ã—å·¥å¤«ã‚’ã—ãªã„ã¨è¡Œã‘ãªã„ã¨ã„ã£ãŸä½œæ¥­ãŒå¤šãå¤§å¤‰ã§ã‚ã‚‹ï¼ãªã®ã§ï¼ŒWindowså‘¨ã‚Šã§ç™ºç”Ÿã™ã‚‹ã‚¨ãƒ©ãƒ¼ã¯å®šæœŸçš„ã«è¨˜äº‹ã«ã—ã¦ã¾ã¨ã‚ã¦ã„ããŸã„æ‰€å­˜

